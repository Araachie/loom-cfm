<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="LOOM-CFM, a method that straightens sampling trajectories in the flow matching framework via storing and exchanging the locally optimal data-noise couplings across minibatches.">
  <meta name="keywords" content="LOOM-CFM, Generative Models, Flow Matching">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Faster Inference of Flow-Based Generative Models via Improved Data-Noise Coupling</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://araachie.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://araachie.github.io/cage">
            CAGE
          </a>
          <a class="navbar-item" href="https://araachie.github.io/yoda">
            YODA
          </a>
          <a class="navbar-item" href="https://araachie.github.io/river">
            RIVER
          </a>
          <a class="navbar-item" href="https://araachie.github.io/glass">
            GLASS
          </a>
          <a class="navbar-item" href="https://araachie.github.io/koala">
            KOALA
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Faster Inference of Flow-Based Generative Models via Improved Data-Noise Coupling</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://araachie.github.io">Aram Davtyan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bhAxvCIAAAAJ&hl=en">Leello Tadesse Dadi</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://people.epfl.ch/volkan.cevher">Volkan Cevher</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://cvg.unibe.ch/people/favaro">Paolo Favaro</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Computer Vision Group, Institute of Informatics, University of Bern, Bern, Switzerland</span>
            <span class="author-block"><sup>2</sup>LIONS, EPFL, Lausanne, Switzerland</span>
          </div>

          <div class="is-size-5">
            <h2 class="subtitle has-text-centered">
              <b>at ICLR 2025</b>
            </h2>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=rsGPrJDIhh"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/araachie/loom-cfm"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
        
            </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Conditional Flow Matching (CFM), a simulation-free method for training continuous normalizing flows, provides an efficient alternative
            to diffusion models for key tasks like image and video generation. The performance of CFM in solving these tasks depends on the way data
            is coupled with noise. A recent approach uses minibatch optimal transport (OT) to reassign noise-data pairs in each training step to
            streamline sampling trajectories and thus accelerate inference. However, its optimization is restricted to individual minibatches,
            limiting its effectiveness on large datasets.
          </p>
          <p>
            To address this shortcoming, we introduce <span class="dnerf">LOOM-CFM</span> (Looking Out Of Minibatch-CFM), a
            novel method to extend the scope of minibatch OT by preserving and optimizing these assignments across minibatches over training time.
          </p>
          <p>
             Our approach demonstrates consistent improvements in the sampling speed-quality trade-off across multiple datasets. 
            <span class="dnerf">LOOM-CFM</span> also enhances distillation initialization and supports high-resolution synthesis in latent space training.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <div class="columns is-centered">

        <div class="column">
          <div class="content">
            <h2 class="title is-3">Algorithm</h2>
            <div class="has-text-centered">
              <image src="./static/images/fm.png" width="80%">
            </div>
            <p>
              In diffusion and flow-based generative models, to generate a sample, we start from noise and integrate the learned vector field, until a clean data point is reached. However, numerical integration requires discretization, which introduces errors. Finer discretization reduces errors but increases computational cost, making inference slower. Straighter trajectories would reduce the number of function evaluations (NFE) and speed-up sampling.
            </p>
            <div class="container-center">
              <p>
                <img src="./static/images/independent.png", width="31%">
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <img src="./static/images/ot.png", width="32.4%">
              </p>
            </div>
            <p>
              In flow matching the default way of coupling, or sampling minibatches, is to sample noise and data points independently. This leads to ambiguity during the training, as the same input to the network may have multiple different targets in different minibatches. Resolving this ambiguity though averaging results in learning curved sampling trajectories. Prior work has tackled this problem through locally changing the independent coupling by reassigning noise and data points within each separate minibatch (e.g. by solving local OT). However, this approach does not effectively scale to larger and higher-dimensional data.
            </p>
            <div class="has-text-centered">
              <image src="./static/images/loom.png" width="70%">
            </div>
            <p>
              Similarly to the prior work (e.g. OT-CFM [1] or BatchOT [2]), <span class="dnerf">LOOM-CFM</span> also solves local OT to reassign independently sampled noise-data pairs within a minibatch. However, in contrast to previous approaches, <span class="dnerf">LOOM-CFM</span> works with a fixed set of noise samples and stores the assignments to reuse them as starting points in future minibatches. This procedure allows minibatches to communicate, which leads to finding stricly more globally optimal assignments that the prior work.
              <br>
              To prevent overfitting to the fixed set of noise samples, we propose to store more than one assigned noise sample per data point in the dataset.
              At each training iteration a minibatch of data-noise pairs is obtained by first sampling data points
              and then randomly picking one of the assigned noises. This corresponds to artificially enlarging the
              dataset by duplicating the data points and does not change the underlying data distribution.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <div class="columns is-centered">

        <div class="column">
          <div class="content">
            <h2 class="title is-3">Results</h2>
            <div class="container-center">
              <p>
                <img src="./static/images/fid_plot.png", width="45%">
                <img src="./static/images/curv.png", width="45%">
              </p>
            </div>
            <br>
            <p>
              <b>Highlights</b>:
              <li>
                <span class="dnerf">LOOM-CFM</span> yields straighter sampling trajectories and reduces the FID with 12 NFE by 41% on CIFAR10, 46% on ImageNet-32, and 54% on ImageNet-64 compared to minibatch OT methods;
              </li>
              <li>
                <span class="dnerf">LOOM-CFM</span> serves as an effective initialization for model
                distillation, further enhancing inference speed;
              </li>
              <li>
                <span class="dnerf">LOOM-CFM</span> is compatible with latent flow matching for generating
                higher-resolution outputs.
              </li>
            </p>
            <p>
              For more results and details, check the paper.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
      <pre><code>@inproceedings{davtyan2025faster,
        title={Faster Inference of Flow-Based Generative Models via Improved Data-Noise Coupling},
        author={Aram Davtyan and Leello Tadesse Dadi and Volkan Cevher and Paolo Favaro},
        booktitle={The Thirteenth International Conference on Learning Representations},
        year={2025},
        url={https://openreview.net/forum?id=rsGPrJDIhh}
      }</code></pre>
  </div>
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <div class="columns is-centered">

        <div class="column">
          <div class="content">
            <h2 class="title is-3">References</h2>
            <p>
              [1] Tong, Alexander, et al. "Improving and generalizing flow-based generative models with minibatch optimal transport." Transactions on Machine Learning Research, 2023.
              <br>
              [2] Pooladian, Aram-Alexandre, et al. "Multisample Flow Matching: Straightening Flows with Minibatch Couplings." International Conference on Machine Learning. PMLR, 2023.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from the <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
