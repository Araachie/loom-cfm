name: "ffhq256_latent_ot_cached"

data:
    name: "h5"
    data_root: "./data/ffhq256"
    image_size: 256
    random_flip: True

model:
    in_channels: 4
    out_ch: 4
    input_size: 32
    ch: 256
    ch_mult: [1, 2, 3, 4]
    num_res_blocks: 2
    attn_resolutions: [2, 4, 8]
    dropout: 0.1
    resamp_with_conv: True
    num_heads: 4
    num_head_channels: 64
    ae_config: "kl_f8"
    ae_checkpoint: "./ae_checkpoints/vae-ft-mse-840000-ema-pruned.ckpt"

training:
    num_epochs: 500

    sigma: 0.0000001
    attracting: False
    t_dist: "uniform"

    source: "normal"
    coupling: "ot_cached_seed"
    coupling_params:
        cache_dir: "./data/ffhq256/noise_cache"
        num_caches: 4

    resample_every: 500
    train_after: 0

    use_fp16: False

    ema_decay: 0.9999

    batching:
        batch_size: 32
        num_workers: 4

    optimizer:
        optimizer: "Adam"
        learning_rate: 0.00002
        weight_decay: 0.000
        grad_clip: 1.0
        scheduler_p: 0.0
        num_warmup_steps: 3500

    loss_weights:
        flow_matching_loss: 1.0
        curvature_loss: 0.0

evaluation:
    type: "FID"

    use_fp16: False

    batching:
        batch_size: 4
        num_workers: 4

    num_real_samples_for_fid: 10000
    num_samples_for_fid: 5000
    steps_to_evaluate: ["midpoint-1", "midpoint-2", "midpoint-4", "midpoint-6"]
